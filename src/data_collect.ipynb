{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-28T14:38:59.917830Z",
     "start_time": "2024-09-28T14:38:59.914786Z"
    }
   },
   "source": [
    "import cv2\n",
    "import os\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Configure Data Collection\n",
    "\n",
    "In this step, the goal is to collect multiple images for a specific face orientation, which will be stored in the tmp folder. Assuming that a value of 0 represents someone completely not paying attention, and 100 represents someone completely paying attention, configure the variable below to represent a value between 0 and 100 in terms of attention level.\n",
    "\n",
    "For example, input 0 and record frames not looking at the camera. Input 100 and record frames looking directly at the camera. Input 50 and record frames looking at the camera but not directly at it, etc. Might be worth adding some values in between (25, 75) to make the model more robust.\n",
    "\n",
    "You might also want to go through the frames in the folder later and review each frame to make sure they are represented correctly. If not, you can delete or re-record them. "
   ],
   "id": "514248487109c67d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:39:00.882865Z",
     "start_time": "2024-09-28T14:39:00.881058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RECORDING_ATTENTION_LEVEL = 100\n",
    "FRAMES_PER_SECOND = 1\n",
    "COUNTDOWN_BEFORE_RECORDING = 3\n",
    "NUMBER_OF_FRAMES_TO_RECORD = 0 # 0 for infinite. If > 1, it will stop after recording the number of frames specified."
   ],
   "id": "5fd8b401dc2a4254",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:39:01.323956Z",
     "start_time": "2024-09-28T14:39:01.320934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "assert 0 <= RECORDING_ATTENTION_LEVEL <= 100\n",
    "\n",
    "# Initialize folder if it doesn't exist\n",
    "root_path = os.path.dirname(os.getcwd())\n",
    "collection_path = os.path.join(root_path, 'tmp', 'data', str(RECORDING_ATTENTION_LEVEL))\n",
    "if not os.path.exists(collection_path):\n",
    "    os.makedirs(collection_path)"
   ],
   "id": "517e08d40c605afa",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T14:39:19.778069Z",
     "start_time": "2024-09-28T14:39:01.971966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Show camera feed on jupyter notebook\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Countdown before recording\n",
    "for i in range(COUNTDOWN_BEFORE_RECORDING):\n",
    "    print(COUNTDOWN_BEFORE_RECORDING - i)\n",
    "    cv2.waitKey(1000)\n",
    "print(\"Recording!\")\n",
    "\n",
    "number_of_frames_recorded = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()    \n",
    "    if cv2.waitKey(int(1000 / FRAMES_PER_SECOND)) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        break\n",
    "        \n",
    "    # Save frame\n",
    "    file_name = f\"{time.time()}.jpg\"\n",
    "    file_path = os.path.join(collection_path, file_name)\n",
    "    cv2.imwrite(file_path, frame)\n",
    "    \n",
    "    # If we are limiting the number of frames to record, check if we have reached the limit\n",
    "    number_of_frames_recorded += 1\n",
    "    if NUMBER_OF_FRAMES_TO_RECORD > 0 and number_of_frames_recorded >= NUMBER_OF_FRAMES_TO_RECORD:\n",
    "        break\n",
    "        \n",
    "cap.release()"
   ],
   "id": "a8c4549321762115",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "1\n",
      "Recording!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     13\u001B[0m     ret, frame \u001B[38;5;241m=\u001B[39m cap\u001B[38;5;241m.\u001B[39mread()    \n\u001B[0;32m---> 14\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwaitKey\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mFRAMES_PER_SECOND\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m&\u001B[39m \u001B[38;5;241m0xFF\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mord\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mq\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m     15\u001B[0m         cap\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m     16\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f4b168c0fbb3ead2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
